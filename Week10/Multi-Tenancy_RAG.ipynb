{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "411dbf39-ae3d-4bdf-95d2-dc777881a813",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2024-04-03 17:37:09--  https://arxiv.org/pdf/2312.04511.pdf\n",
      "Resolving arxiv.org (arxiv.org)... 151.101.195.42, 151.101.131.42, 151.101.67.42, ...\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.195.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 885090 (864K) [application/pdf]\n",
      "Saving to: 'llm_compiler.pdf'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  5% 1.81M 0s\n",
      "    50K .......... .......... .......... .......... .......... 11% 4.95M 0s\n",
      "   100K .......... .......... .......... .......... .......... 17% 3.65M 0s\n",
      "   150K .......... .......... .......... .......... .......... 23% 4.47M 0s\n",
      "   200K .......... .......... .......... .......... .......... 28% 7.75M 0s\n",
      "   250K .......... .......... .......... .......... .......... 34% 11.2M 0s\n",
      "   300K .......... .......... .......... .......... .......... 40% 20.2M 0s\n",
      "   350K .......... .......... .......... .......... .......... 46% 5.43M 0s\n",
      "   400K .......... .......... .......... .......... .......... 52% 10.4M 0s\n",
      "   450K .......... .......... .......... .......... .......... 57% 10.5M 0s\n",
      "   500K .......... .......... .......... .......... .......... 63% 18.6M 0s\n",
      "   550K .......... .......... .......... .......... .......... 69% 13.5M 0s\n",
      "   600K .......... .......... .......... .......... .......... 75% 20.3M 0s\n",
      "   650K .......... .......... .......... .......... .......... 80% 6.92M 0s\n",
      "   700K .......... .......... .......... .......... .......... 86% 8.92M 0s\n",
      "   750K .......... .......... .......... .......... .......... 92% 9.77M 0s\n",
      "   800K .......... .......... .......... .......... .......... 98% 12.1M 0s\n",
      "   850K .......... ....                                       100%  296M=0.1s\n",
      "\n",
      "2024-04-03 17:37:10 (6.88 MB/s) - 'llm_compiler.pdf' saved [885090/885090]\n",
      "\n",
      "--2024-04-03 17:37:10--  https://arxiv.org/pdf/2312.06648.pdf\n",
      "Resolving arxiv.org (arxiv.org)... 151.101.195.42, 151.101.131.42, 151.101.67.42, ...\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.195.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1103758 (1.1M) [application/pdf]\n",
      "Saving to: 'dense_x_retrieval.pdf'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  4% 1.82M 1s\n",
      "    50K .......... .......... .......... .......... ..........  9% 7.22M 0s\n",
      "   100K .......... .......... .......... .......... .......... 13% 3.00M 0s\n",
      "   150K .......... .......... .......... .......... .......... 18% 8.08M 0s\n",
      "   200K .......... .......... .......... .......... .......... 23% 9.69M 0s\n",
      "   250K .......... .......... .......... .......... .......... 27% 9.88M 0s\n",
      "   300K .......... .......... .......... .......... .......... 32% 5.27M 0s\n",
      "   350K .......... .......... .......... .......... .......... 37% 16.9M 0s\n",
      "   400K .......... .......... .......... .......... .......... 41% 17.4M 0s\n",
      "   450K .......... .......... .......... .......... .......... 46% 14.8M 0s\n",
      "   500K .......... .......... .......... .......... .......... 51% 10.8M 0s\n",
      "   550K .......... .......... .......... .......... .......... 55% 4.08M 0s\n",
      "   600K .......... .......... .......... .......... .......... 60% 17.1M 0s\n",
      "   650K .......... .......... .......... .......... .......... 64% 8.59M 0s\n",
      "   700K .......... .......... .......... .......... .......... 69% 50.7M 0s\n",
      "   750K .......... .......... .......... .......... .......... 74% 31.5M 0s\n",
      "   800K .......... .......... .......... .......... .......... 78% 21.3M 0s\n",
      "   850K .......... .......... .......... .......... .......... 83% 34.9M 0s\n",
      "   900K .......... .......... .......... .......... .......... 88% 30.4M 0s\n",
      "   950K .......... .......... .......... .......... .......... 92% 24.4M 0s\n",
      "  1000K .......... .......... .......... .......... .......... 97% 34.5M 0s\n",
      "  1050K .......... .......... .......                         100% 24.2M=0.1s\n",
      "\n",
      "2024-04-03 17:37:10 (8.67 MB/s) - 'dense_x_retrieval.pdf' saved [1103758/1103758]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2312.04511.pdf\" -O \"llm_compiler.pdf\"\n",
    "!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2312.06648.pdf\" -O \"dense_x_retrieval.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0782811c-67b3-4f4c-85bd-0413a425699b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.llms.llama_cpp import LlamaCPP\n",
    "from llama_index.llms.llama_cpp.llama_utils import messages_to_prompt, completion_to_prompt\n",
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.retrievers import BaseRetriever, VectorIndexRetriever, RecursiveRetriever\n",
    "from llama_index.core.ingestion import IngestionPipeline, IngestionCache\n",
    "from llama_index.core.vector_stores import MetadataFilters, ExactMatchFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb46b480-3fd7-4025-8718-dae42b1fc313",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = SimpleDirectoryReader(input_files=['dense_x_retrieval.pdf'])\n",
    "documents_jerry = reader.load_data()\n",
    "\n",
    "reader = SimpleDirectoryReader(input_files=['llm_compiler.pdf'])\n",
    "documents_ravi = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0f46ab2-9656-4075-aac0-3d893ab13e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents_jerry) # 18 page pdf file loaded as 18 documents "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b5dcf3-8aab-41a2-b796-d21b6fb0775e",
   "metadata": {},
   "source": [
    "# Create An Empty Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdc90631-b416-47f3-a15b-63f31e4cf11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d8c5d90128245c88c3c378694388ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/777 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a81b9864ebe437da71199ef41ba7d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9544a0503f249a3ae3de5790697f730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8688a0ed5d4352a1f170a13c4630cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c657e5658543188cd8793f05873366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d19345889ce4f8492c5ee1c526b0885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define embedding function\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9dcb319-5ae5-4db4-91fb-d36e19fab63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter, SemanticSplitterNodeParser\n",
    "splitter = SemanticSplitterNodeParser(buffer_size=1, breakpoint_percentile_threshold=95, embed_model=embed_model) #slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "566eec9c-3b89-4204-a78f-b946c58bd207",
   "metadata": {},
   "outputs": [],
   "source": [
    "semant_nodes = splitter.get_nodes_from_documents(documents_jerry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f1636fb-2624-40ac-8670-e543b63867c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(semant_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53fd704c-7549-4802-98c7-f00fd22c95a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LlamaCPP(\n",
    "    # You can pass in the URL to a GGML model to download it automatically\n",
    "    model_path='../../llama2/llama-2-7b-chat.Q8_0.gguf',\n",
    "    temperature=0.01,\n",
    "    context_window=3900,  \n",
    "    # kwargs to pass to __call__()\n",
    "    model_kwargs={\"n_gpu_layers\": 3, \"offload_kqv\": True}, #onyl 1 layer in GPU, others in CPU, if you do not how many layers, set to -1\n",
    "    # transform inputs into Llama2 format\n",
    "    verbose=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c6be8c-a15d-45b3-8fd4-f104670bfc1d",
   "metadata": {},
   "source": [
    "# Create An Empty Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c7f1038-d6d1-4b3e-b0c1-045b722caaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents=[], embed_model = embed_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2432500-41a4-4f11-aabc-fcf347cdc070",
   "metadata": {},
   "source": [
    "# Ingestion Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a71b1d6c-a714-4bdd-b084-55f1f3e39371",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(chunk_size=512, chunk_overlap=20),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0b57ac-22a8-4766-a455-7c529779ea5a",
   "metadata": {},
   "source": [
    "# Update metadata and insert document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2a6473b-d913-41e8-a046-ab5493f03c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For user Jerry\n",
    "for document in documents_jerry:\n",
    "    document.metadata['user'] = 'Jerry'\n",
    "\n",
    "nodes = pipeline.run(documents=documents_jerry)\n",
    "# Insert nodes into the index\n",
    "index.insert_nodes(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ebc9579-456a-4c6e-a334-1267a9c7985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For user Ravi\n",
    "for document in documents_ravi:\n",
    "    document.metadata['user'] = 'Ravi'\n",
    "\n",
    "nodes = pipeline.run(documents=documents_ravi)\n",
    "# Insert nodes into the index\n",
    "index.insert_nodes(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8e3c1e-3a28-4e32-941a-fb86408266a7",
   "metadata": {},
   "source": [
    "# Define Query Engines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2cc15bda-43b7-4d84-a1a3-1efcfb7ba6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Jerry\n",
    "jerry_query_engine = index.as_query_engine(llm = llm, streaming=True,\n",
    "    filters=MetadataFilters(\n",
    "        filters=[\n",
    "            ExactMatchFilter(\n",
    "                key=\"user\",\n",
    "                value=\"Jerry\",\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    similarity_top_k=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e8f6ea3a-0054-4d36-8bc6-b6684e34f570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Ravi\n",
    "ravi_query_engine = index.as_query_engine(llm = llm, streaming=True,\n",
    "    filters=MetadataFilters(\n",
    "        filters=[\n",
    "            ExactMatchFilter(\n",
    "                key=\"user\",\n",
    "                value=\"Ravi\",\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    similarity_top_k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7343c7-3afa-4cd7-983c-62ae5fcf21bd",
   "metadata": {},
   "source": [
    "# Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "12fd96ea-5f77-4418-8929-92b74bf3a827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Propositions are not explicitly mentioned in the paper, but the authors propose using them as a retrieval unit for dense retrieval models. They explain that each proposition should correspond to a distinct piece of meaning in text, and should be minimal, contextualized, and self-contained. They also demonstrate the concept of proposition and how a passage can be split into its set of propositions using an example on the left side of Figure 2. They expect each proposition to describe exactly one contextualized atomic fact, and so their intuition is that propositions would suitably work as a retrieval unit for information-seeking questions. They empirically compare the use of 100-word passages, sentences, and propositions as retrieval units on Wikipedia, a commonly-used retrieval source for knowledge-intensive NLP tasks, and find that propositions work best. They also train a model called the Propositionizer to generate propositions from a given passage, and use it to finetune a Flan-T5-Large model."
     ]
    }
   ],
   "source": [
    "jerry_query_engine.query(\"what are propositions mentioned in the paper?\").print_response_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ba8c54e4-dbc6-49d6-b307-10874068bed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The steps involved in LLMCompiler are as follows:\n",
      "Step 1: User Provides Tool Definitions and In-Context Examples for the Planner (Sec. A.3.2)\n",
      "Step 2: The Planner Generates a Sequence of Tasks and Their Dependencies Using the Provided Tool Definitions and In-Context Examples (Sec. A.3.1)\n",
      "Step 3: The Task Fetching Unit Fetches Tasks to the Executor Based on a Greedy Policy (Sec. A.3.1)\n",
      "Step 4: The Executor Executes the Fetched Tasks in Parallel (Sec. A.4)\n",
      "Note that the steps are not mutually exclusive, and the Planner may use the provided tool definitions and in-context examples to generate tasks and their dependencies, and then the Task Fetching Unit may fetch tasks to the Executor based on a greedy policy, and the Executor may execute the fetched tasks in parallel."
     ]
    }
   ],
   "source": [
    "# Ravi has LLMCompiler paper\n",
    "ravi_query_engine.query(\"what are steps involved in LLMCompiler?\").print_response_stream()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
